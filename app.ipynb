{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('creditcard.csv')\n",
    "#display all rows\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"First 5 rows:\\n{credit_data.head(5)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 rows:\n",
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Last 5 rows:\\n{credit_data.tail()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "Dataset information:\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Dataset information:\\n{credit_data.info()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Missing values per column:\\n{credit_data.isnull().sum()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Class distribution:\\n{credit_data['Class'].value_counts()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: The target variable 'Class' is imbalanced, with 0 representing legitimate transactions and 1 representing fraudulent transactions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating data based on class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_data = credit_data[credit_data['Class'] == 0]\n",
    "fraud_data = credit_data[credit_data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing statistical measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate transactions - Amount statistics:\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "Fraudulent transactions - Amount statistics:\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "Mean values by class:\n",
      "               Time        V1        V2        V3        V4        V5  \\\n",
      "Class                                                                   \n",
      "0      94838.202258  0.008258 -0.006271  0.012171 -0.007860  0.005453   \n",
      "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
      "\n",
      "             V6        V7        V8        V9  ...       V20       V21  \\\n",
      "Class                                          ...                       \n",
      "0      0.002419  0.009637 -0.000987  0.004467  ... -0.000644 -0.001235   \n",
      "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
      "\n",
      "            V22       V23       V24       V25       V26       V27       V28  \\\n",
      "Class                                                                         \n",
      "0     -0.000024  0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   \n",
      "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
      "\n",
      "           Amount  \n",
      "Class              \n",
      "0       88.291022  \n",
      "1      122.211321  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Legitimate transactions - Amount statistics:\\n{legit_data['Amount'].describe()}\\n\")\n",
    "print(f\"Fraudulent transactions - Amount statistics:\\n{fraud_data['Amount'].describe()}\\n\")\n",
    "print(f\"Mean values by class:\\n{credit_data.groupby('Class').mean()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Under-sampling legitimate transactions to match fraudulent transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_fraud = fraud_data.shape[0]\n",
    "legit_sample = legit_data.sample(n=num_fraud, random_state=42)\n",
    "new_dataset = pd.concat([legit_sample, fraud_data], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Checking the new dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset head:\n",
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "138028   82450.0  1.314539  0.590643 -0.666593  0.716564  0.301978 -1.125467   \n",
      "63099    50554.0 -0.798672  1.185093  0.904547  0.694584  0.219041 -0.319295   \n",
      "73411    55125.0 -0.391128 -0.245540  1.122074 -1.308725 -0.639891  0.008678   \n",
      "164247  116572.0 -0.060302  1.065093 -0.987421 -0.029567  0.176376 -1.348539   \n",
      "148999   90434.0  1.848433  0.373364  0.269272  3.866438  0.088062  0.970447   \n",
      "\n",
      "              V7        V8        V9  ...       V21       V22       V23  \\\n",
      "138028  0.388881 -0.288390 -0.132137  ... -0.170307 -0.429655 -0.141341   \n",
      "63099   0.495236  0.139269 -0.760214  ...  0.202287  0.578699 -0.092245   \n",
      "73411  -0.701304 -0.027315 -2.628854  ... -0.133485  0.117403 -0.191748   \n",
      "164247  0.775644  0.134843 -0.149734  ...  0.355576  0.907570 -0.018454   \n",
      "148999 -0.721945  0.235983  0.683491  ...  0.103563  0.620954  0.197077   \n",
      "\n",
      "             V24       V25       V26       V27       V28  Amount  Class  \n",
      "138028 -0.200195  0.639491  0.399476 -0.034321  0.031692    0.76      0  \n",
      "63099   0.013723 -0.246466 -0.380057 -0.396030 -0.112901    4.18      0  \n",
      "73411  -0.488642 -0.309774  0.008100  0.163716  0.239582   15.00      0  \n",
      "164247 -0.126269 -0.339923 -0.150285 -0.023634  0.042330   57.00      0  \n",
      "148999  0.692392 -0.206530 -0.021328 -0.019823 -0.042682    0.00      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "New dataset tail:\n",
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
      "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
      "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
      "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
      "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
      "\n",
      "              V7        V8        V9  ...       V21       V22       V23  \\\n",
      "279863 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
      "280143 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
      "280149 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
      "281144 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
      "281674  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
      "\n",
      "             V24       V25       V26       V27       V28  Amount  Class  \n",
      "279863 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
      "280143 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
      "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
      "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
      "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "New dataset class distribution:\n",
      "0    492\n",
      "1    492\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "New dataset mean values by class:\n",
      "               Time        V1        V2        V3        V4        V5  \\\n",
      "Class                                                                   \n",
      "0      95052.758130  0.153312  0.009649 -0.038029 -0.027323  0.061966   \n",
      "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
      "\n",
      "             V6        V7        V8        V9  ...       V20       V21  \\\n",
      "Class                                          ...                       \n",
      "0     -0.053962  0.013795  0.014911  0.037348  ...  0.015030  0.014059   \n",
      "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
      "\n",
      "            V22       V23       V24       V25       V26       V27       V28  \\\n",
      "Class                                                                         \n",
      "0     -0.020781  0.013223 -0.007257  0.024646 -0.027696  0.011070 -0.002305   \n",
      "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
      "\n",
      "           Amount  \n",
      "Class              \n",
      "0       80.348354  \n",
      "1      122.211321  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"New dataset head:\\n{new_dataset.head()}\\n\")\n",
    "print(f\"New dataset tail:\\n{new_dataset.tail()}\\n\")\n",
    "print(f\"New dataset class distribution:\\n{new_dataset['Class'].value_counts()}\\n\")\n",
    "print(f\"New dataset mean values by class:\\n{new_dataset.groupby('Class').mean()}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X = new_dataset.drop('Class', axis=1)\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_selected = selector.fit_transform(X_scaled, new_dataset['Class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Splitting data into features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = new_dataset['Class']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Splitting data into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (984, 10)\n",
      "Training set shape: (787, 10), Test set shape: (197, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(f\"Original dataset shape: {X_selected.shape}\")\n",
    "print(f\"Training set shape: {X_train.shape}, Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9365\n",
      "Test accuracy: 0.9594\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        99\n",
      "           1       0.99      0.93      0.96        98\n",
      "\n",
      "    accuracy                           0.96       197\n",
      "   macro avg       0.96      0.96      0.96       197\n",
      "weighted avg       0.96      0.96      0.96       197\n",
      "\n",
      "Confusion Matrix:\n",
      "[[98  1]\n",
      " [ 7 91]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- README.md -->\n",
    "<style>\n",
    "h1 {\n",
    "  color: #333;\n",
    "  font-family: Arial, sans-serif;\n",
    "  text-align: center;\n",
    "}\n",
    "\n",
    "h2 {\n",
    "  color: #666;\n",
    "  font-family: Arial, sans-serif;\n",
    "}\n",
    "\n",
    "code {\n",
    "  background-color: #f5f5f5;\n",
    "  padding: 2px 4px;\n",
    "  font-family: Consolas, monospace;\n",
    "  border-radius: 4px;\n",
    "}\n",
    "\n",
    "p {\n",
    "  font-family: Arial, sans-serif;\n",
    "  line-height: 1.5;\n",
    "}\n",
    "\n",
    ".highlighted {\n",
    "  color: #e83e8c;\n",
    "  font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "# Predictive Modeling for Credit Card Fraud Detection\n",
    "\n",
    "This project focuses on building a machine learning model to detect fraudulent credit card transactions. The dataset used is highly imbalanced, with a significantly higher number of legitimate transactions compared to fraudulent ones.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "The code starts by loading the dataset and performing exploratory data analysis (EDA) to understand the data distribution, missing values, and class imbalance. To address the imbalance, the legitimate transactions are undersampled to match the number of fraudulent transactions, creating a balanced dataset.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "The code then applies feature scaling using <code class=\"highlighted\">StandardScaler</code> to ensure that all features are on a similar scale. Additionally, feature selection is performed using <code class=\"highlighted\">SelectKBest</code> and <code class=\"highlighted\">f_classif</code> to identify the top 10 most relevant features for the classification task.\n",
    "\n",
    "## Model Training and Evaluation\n",
    "\n",
    "The data is split into training and testing sets, and a Logistic Regression model is trained. To find the optimal hyperparameters, a <code class=\"highlighted\">GridSearchCV</code> is employed with a range of regularization strengths (<code class=\"highlighted\">C</code> values) for the Logistic Regression model.\n",
    "\n",
    "The trained model is then evaluated on both the training and testing sets using various metrics, including accuracy, classification report, and confusion matrix. The classification report provides valuable insights into the model's performance for each class, including precision, recall, and F1-score. The confusion matrix helps identify the number of true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The provided code demonstrates a complete pipeline for credit card fraud detection, from data exploration and preprocessing to model training, hyperparameter tuning, and evaluation. By addressing the class imbalance, performing feature engineering, and leveraging appropriate evaluation metrics, this approach aims to build a robust and reliable model for identifying fraudulent transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"background-color: #f0f0f0; padding: 20px; border-radius: 5px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); text-align: center;\">\n",
    "  <h2 style=\"color: #333;\">Thank you for visiting!</h2>\n",
    "  <p style=\"color: #666;\">Your feedback and contributions are highly appreciated.</p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
